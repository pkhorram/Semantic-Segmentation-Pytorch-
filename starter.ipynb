{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CityScapesDataset(csv_file='train.csv')\n",
    "val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=4,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=4,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=4,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.bias.data.view(m.bias.data.shape[0],1))\n",
    "        \n",
    "        \n",
    "epochs     = 100\n",
    "criterion = torch.nn.CrossEntropyLoss()# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "# Fix magic number\n",
    "fcn_model = FCN(n_class=34)\n",
    "fcn_model.apply(init_weights)\n",
    "#fcn_model = torch.load('best_model')\n",
    "optimizer = optim.Adam(fcn_model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        a = math.sqrt(3) * math.sqrt(2/m.bias.data.shape[0])\n",
    "        torch.nn.init._no_grad_uniform_(m.bias.data, -a, a)\n",
    "        #torch.nn.init.xavier_uniform_(m.bias.data)\n",
    "        \n",
    "\n",
    "#criterion = torch.nn.CrossEntropyLoss()# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "# Fix magic number\n",
    "\n",
    "#fcn_model = torch.load('best_model')\n",
    "#optimizer = optim.Adam(fcn_model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old script for train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_gpu = torch.cuda.is_available()\n",
    "# if use_gpu:\n",
    "    \n",
    "#     device = torch.device(\"cuda:0\")\n",
    "#     #print(device.index)\n",
    "#     #fcn_model = fcn_model.to(device)\n",
    "#     fcn_model = torch.nn.DataParallel(fcn_model, output_device=device)\n",
    "#     #print(fcn_model.device_ids)\n",
    "    \n",
    "    \n",
    "def train(model, epochs, train_loader, val_loader, test_loader):\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        \n",
    "        \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = X.to(device)# Move your inputs onto the gpu\n",
    "                labels = Y.to(device) # Move your labels onto the gpu\n",
    "            else:\n",
    "                inputs, labels = X, Y # Unpack variables into inputs and labels\n",
    "                \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, Variable(labels.long()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "                \n",
    "                \n",
    "            # Checking if early stop conditions met\n",
    "            #if early_stop and i > early_stop_epoch:\n",
    "             #   shouldStop = True\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        torch.save(model, 'best_model')\n",
    "\n",
    "        val(epoch)\n",
    "        model.train()\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    \n",
    "    # set to evaluation mode \n",
    "    fcn_model.eval()\n",
    "\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    loss = []\n",
    "    pred = []\n",
    "    acc = []\n",
    "    \n",
    "    IOU_init = False\n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,tar.shape[1]))\n",
    "            \n",
    "        if use_gpu:\n",
    "            inputs = X.to(device)\n",
    "            labels = Y.to(device)\n",
    "            tar = tar.to(device)\n",
    "        else:\n",
    "            inputs, labels, tar = X, Y, tar \n",
    "\n",
    "        print('inputs.device', inputs.device)    \n",
    "\n",
    "        outputs = fcn_model(inputs)\n",
    "        loss.append(criterion(outputs, Variables(tar.long())))\n",
    "        prediction = softmax(outputs) \n",
    "        acc.append(pixel_acc(prediction, labels))\n",
    "        IOU = IOU + np.array(iou(pred, Y))\n",
    "    \n",
    "    acc = sum(acc)/len(acc)\n",
    "    avg_loss = sum(loss)/len(loss) \n",
    "    IOU = IOU/iter  \n",
    "    \n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    \n",
    "    return avg_loss, acc, IOU      \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "def test():\n",
    "    \n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    pred = []\n",
    "    acc = []\n",
    "    \n",
    "    IOU_init = False\n",
    "    for iter, (X, tar, Y) in enumerate(test_loader):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,tar.shape[1]))\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = X.to(device)\n",
    "            labels = Y.to(device)\n",
    "            tar = tar.to(device)\n",
    "        else:\n",
    "            inputs, labels, tar = X, Y, tar \n",
    "                \n",
    "        print('inputs.device', inputs.device)    \n",
    "\n",
    "        outputs = fcn_model(inputs)  \n",
    "        print(output.shape)\n",
    "        prediction = softmax(outputs)\n",
    "        acc.append(pixel_acc(prediction, labels))\n",
    "        IOU = IOU + np.array(iou(prediction, Y))\n",
    "        \n",
    "    acc = sum(acc)/len(acc)        \n",
    "    IOU = IOU/iter\n",
    "\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    \n",
    "    return acc, IOU\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train_dataset = CityScapesDataset(csv_file='train.csv')\n",
    "    val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "    test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=2,\n",
    "                              num_workers=2,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                              batch_size=2,\n",
    "                              num_workers=2,\n",
    "                              shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=2,\n",
    "                              num_workers=2,\n",
    "                              shuffle=True)\n",
    "    \n",
    "    \n",
    "    fcn_model = FCN(n_class=34)\n",
    "    fcn_model.apply(init_weights)\n",
    "    #val(0)  # show the accuracy before training\n",
    "    epochs     = 100\n",
    "    train(fcn_model, epochs, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New script for train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a025731466ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m#val(0)  # show the accuracy before training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a025731466ff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    fcn_model = fcn_model.cuda()\n",
    "    \n",
    "def train():\n",
    "\n",
    "    \n",
    "    val_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        \n",
    "        print(np.array(val_loss).shape)\n",
    "        # early-stopping \n",
    "        if epoch > 11:\n",
    "            if val_loss[-1] < val_loss[-10]:\n",
    "                open('save_param', 'w').close()\n",
    "                torch.save(fcn_model.state_dict(), 'save_param')\n",
    "                \n",
    "                  \n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = X.to('cuda')# Move your inputs onto the gpu\n",
    "                labels = Y.to('cuda') # Move your labels onto the gpu\n",
    "            else:\n",
    "                inputs, labels = X, Y # Unpack variables into inputs and labels\n",
    "                \n",
    "            outputs = fcn_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "                \n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        torch.save(fcn_model, 'best_model')\n",
    "\n",
    "        avg_loss, acc, IOU = val(epoch)\n",
    "        val_loss.append(avg_loss) \n",
    "        fcn_model.train()\n",
    "\n",
    "\n",
    "def val(epoch):\n",
    "    \n",
    "    # set to evaluation mode \n",
    "    fcn_model.eval()\n",
    "\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    loss = []\n",
    "    pred = []\n",
    "    acc = []\n",
    "    \n",
    "    IOU_init = False\n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,tar.shape[1]))\n",
    "            \n",
    "        if use_gpu:\n",
    "            inputs = X.to('cuda')\n",
    "            labels = Y.to('cuda')\n",
    "            \n",
    "        else:\n",
    "            inputs, labels = X, Y\n",
    "\n",
    "            \n",
    "        with torch.no_grad():   \n",
    "            outputs = fcn_model(inputs)    \n",
    "            loss.append(criterion(outputs, labels))\n",
    "            prediction = softmax(outputs) \n",
    "            acc.append(pixel_acc(prediction, labels))\n",
    "            IOU = IOU + np.array(iou(prediction, labels))\n",
    "        \n",
    "    \n",
    "    acc = sum(acc)/len(acc)\n",
    "    avg_loss = sum(loss)/len(loss) \n",
    "    IOU = IOU/iter  \n",
    "    \n",
    "    return avg_loss, acc, IOU      \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "def test():\n",
    "    \n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    pred = []\n",
    "    acc = []\n",
    "    \n",
    "    IOU_init = False\n",
    "    for iter, (X, tar, Y) in enumerate(test_loader):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,tar.shape[1]))\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = X.to('cuda')\n",
    "            labels = Y.to('cuda')\n",
    "            tar = tar.to('cuda')\n",
    "        else:\n",
    "            inputs, labels, tar = X, Y, tar \n",
    "                    \n",
    "        \n",
    "        outputs = fcn_model(inputs)  \n",
    "        print(output.shape)\n",
    "        prediction = softmax(outputs)\n",
    "        acc.append(pixel_acc(prediction, labels))\n",
    "        IOU = IOU + np.array(iou(prediction, Y))\n",
    "        \n",
    "    acc = sum(acc)/len(acc)        \n",
    "    IOU = IOU/iter\n",
    "\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    \n",
    "    return acc, IOU\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #val(0)  # show the accuracy before training\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model.load_state_dict(torch.load('./save_param'))\n",
    "fcn_model.parameters()\n",
    "for p in fcn_model.parameters():\n",
    "    print(p.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
