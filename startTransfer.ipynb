{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from dataloader import *\n",
    "from transfer import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.bias.data.view(m.bias.data.shape[0],1))\n",
    "        #a = math.sqrt(3) * math.sqrt(2/m.bias.data.shape[0])\n",
    "        #torch.nn.init._no_grad_uniform_(m.bias.data, -a, a)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def train(model, criterion, epochs, train_loader, val_loader, test_loader, use_gpu, name, debug=False):\n",
    "    if debug:\n",
    "        initMem = {}\n",
    "        print(\"Initialized with\")\n",
    "        initMem = checkM(initMem)\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Use GPU:  \")\n",
    "        initMem = checkM(initMem)\n",
    "        \n",
    "    \n",
    "    val_loss_set = []\n",
    "    val_acc_set = []\n",
    "    val_iou_set = []\n",
    "    \n",
    "    # Early Stop criteria\n",
    "    minLoss = 1e6\n",
    "    minLossIdx = 0\n",
    "    earliestStopEpoch = 10\n",
    "    earlyStopDelta = 5\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "             \n",
    "                  \n",
    "        if debug:\n",
    "            singleM = {}\n",
    "            \n",
    "        for iter, (inputs, tar, labels) in enumerate(train_loader):\n",
    "            \n",
    "            #print(inputs.shape)\n",
    "            optimizer.zero_grad()\n",
    "            #print(\"\\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "            #startMem = checkM(startMem)\n",
    "            #singleM = checkM(singleM)\n",
    "            \n",
    "            del tar\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.to(device)# Move your inputs onto the gpu\n",
    "                labels = labels.to(device) # Move your labels onto the gpu\n",
    "            \n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            del inputs\n",
    "            loss = criterion(outputs, Variable(labels.long()))\n",
    "            del labels\n",
    "            del outputs\n",
    "            \n",
    "            if debug:\n",
    "                print(\"\\n**********************************************\\nPost Loss\")\n",
    "                #backMem = checkM(backMem, True)\n",
    "                singleM = checkM(singleM)\n",
    "                #print(\"start vs back diff\")\n",
    "                #memDiff(startMem, backMem)\n",
    "            loss.backward()\n",
    "            loss = loss.item()\n",
    "            \n",
    "            if debug:\n",
    "                print(\"\\n**********************************************\\nPost Backward\")\n",
    "                #postLossMem = checkM(postLossMem, True)\n",
    "                #print(\"Post loss vs back diff\")\n",
    "                singleM = checkM(singleM)\n",
    "                #memDiff(backMem, postLossMem)\n",
    "                \n",
    "            optimizer.step()\n",
    "            \n",
    "            if debug:\n",
    "                print(\"\\n**********************************************\\nPost Step\")\n",
    "                singleM = checkM(singleM)\n",
    "                #finalMem = checkM(finalMem, True)\n",
    "                #memDiff(postLossMem, finalMem)\n",
    "            \n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss))\n",
    "            \n",
    "            if debug:    \n",
    "                print(\"\\n**********************************************\\nFinal\")\n",
    "                singleM = checkM(singleM)\n",
    "            \n",
    "                print(\"\\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\")\n",
    "        \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        \n",
    "        # calculate val loss each epoch\n",
    "        val_loss, val_acc, val_iou = val(model, val_loader, criterion, use_gpu)\n",
    "        val_loss_set.append(val_loss)\n",
    "        val_acc_set.append(val_acc)\n",
    "        val_iou_set.append(val_iou)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < minLoss:\n",
    "            # Store new best\n",
    "            torch.save(model, name)\n",
    "            minLoss = val_loss\n",
    "            minLossIdx = epoch\n",
    "            \n",
    "        # If passed min threshold, and no new min has been reached for delta epochs\n",
    "        elif epoch > earliestStopEpoch and (epoch - minLossIdx) > earlyStopDelta:\n",
    "            print(\"Stopping early at {}\".format(minLossIdx))\n",
    "            break\n",
    "        # TODO what is this for?\n",
    "        #model.train()\n",
    "        \n",
    "    return val_loss_set, val_acc_set, val_iou_set\n",
    "\n",
    "\n",
    "def val(model, val_loader, criterion, use_gpu):\n",
    "    \n",
    "    # set to evaluation mode \n",
    "    model.eval()\n",
    "\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    loss = []\n",
    "    pred = []\n",
    "    acc = []\n",
    "    \n",
    "    IOU_init = False\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        \n",
    "        #model.to(device)\n",
    "        \n",
    "    for iter, (inputs, tar, labels) in tqdm(enumerate(val_loader)):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,19))\n",
    "        del tar\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "\n",
    "            \n",
    "        with torch.no_grad():   \n",
    "            outputs = model(inputs)  \n",
    "            del inputs\n",
    "            loss.append(criterion(outputs, labels.long()).item())\n",
    "            prediction = softmax(outputs) \n",
    "            del outputs\n",
    "            acc.append(pixel_acc(prediction, labels))\n",
    "            IOU = IOU + np.array(iou(prediction, labels))\n",
    "            del prediction\n",
    "            del labels\n",
    "        \n",
    "    \n",
    "    acc = sum(acc)/len(acc)\n",
    "    avg_loss = sum(loss)/len(loss) \n",
    "    IOU = IOU/iter  \n",
    "    \n",
    "    return avg_loss, acc, IOU      \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "def test(model, use_gpu):\n",
    "    \n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    pred = []\n",
    "    acc = []\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        \n",
    "        model.to(device)\n",
    "    \n",
    "    IOU_init = False\n",
    "    for iter, (X, tar, Y) in enumerate(test_loader):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,tar.shape[1]))\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = X.to(device)\n",
    "            labels = Y.to(device)\n",
    "        else:\n",
    "            inputs, labels = X, Y\n",
    "                    \n",
    "        \n",
    "        outputs = model(inputs)  \n",
    "        \n",
    "        prediction = softmax(outputs)\n",
    "        acc.append(pixel_acc(prediction, labels))\n",
    "        IOU = IOU + np.array(iou(prediction, Y))\n",
    "        \n",
    "    acc = sum(acc)/len(acc)        \n",
    "    IOU = IOU/iter\n",
    "\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    \n",
    "    return acc, IOU\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        news = self.shape.copy()\n",
    "        news[0] =  x.shape[0]\n",
    "        \n",
    "        return x.view(*tuple(news))\n",
    "\n",
    "def getTransferModel(n_class):\n",
    "    \n",
    "    decoder = nn.Sequential(\n",
    "        Reshape([1,512,32,64]),\n",
    "        \n",
    "        nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ),\n",
    "        \n",
    "        nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ),\n",
    "            \n",
    "        nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ),\n",
    "            \n",
    "        nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ),\n",
    "        \n",
    "            \n",
    "        nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ),\n",
    "\n",
    "        nn.Conv2d(32, n_class, kernel_size=1)\n",
    "        )\n",
    "    decoder.apply(init_weights)\n",
    "        \n",
    "\n",
    "    \n",
    "    model = models.resnet34(pretrained=True)\n",
    "        \n",
    "    for param in model.parameters():\n",
    "        # False implies no retraining\n",
    "        param.requires_grad=False\n",
    "        \n",
    "    del param\n",
    "\n",
    "    model.avgpool = nn.Identity() \n",
    "        \n",
    "    model.fc = decoder\n",
    "    #print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /tmp/xdg-cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:01<00:00, 87.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, loss: 3.845942735671997\n",
      "epoch0, iter10, loss: 2.3750228881835938\n",
      "epoch0, iter20, loss: 1.8411728143692017\n",
      "epoch0, iter30, loss: 1.483833909034729\n",
      "epoch0, iter40, loss: 1.584811806678772\n",
      "epoch0, iter50, loss: 1.606908917427063\n",
      "epoch0, iter60, loss: 1.6197291612625122\n",
      "epoch0, iter70, loss: 1.2697526216506958\n",
      "epoch0, iter80, loss: 1.4819837808609009\n",
      "epoch0, iter90, loss: 1.4046354293823242\n",
      "epoch0, iter100, loss: 1.0655763149261475\n",
      "epoch0, iter110, loss: 2.1386826038360596\n",
      "epoch0, iter120, loss: 1.2468276023864746\n",
      "epoch0, iter130, loss: 1.2104151248931885\n",
      "epoch0, iter140, loss: 1.4500631093978882\n",
      "epoch0, iter150, loss: 0.9676685929298401\n",
      "epoch0, iter160, loss: 1.1298829317092896\n",
      "epoch0, iter170, loss: 1.1464755535125732\n",
      "epoch0, iter180, loss: 1.2244064807891846\n",
      "epoch0, iter190, loss: 0.9130232930183411\n",
      "epoch0, iter200, loss: 1.2994080781936646\n",
      "epoch0, iter210, loss: 1.0322597026824951\n",
      "epoch0, iter220, loss: 1.294190526008606\n",
      "epoch0, iter230, loss: 0.7300000786781311\n",
      "epoch0, iter240, loss: 1.3909763097763062\n",
      "epoch0, iter250, loss: 0.7910811305046082\n",
      "epoch0, iter260, loss: 1.2110782861709595\n",
      "epoch0, iter270, loss: 0.9078946113586426\n",
      "epoch0, iter280, loss: 1.0168322324752808\n",
      "epoch0, iter290, loss: 1.3082044124603271\n",
      "epoch0, iter300, loss: 0.8128883242607117\n",
      "epoch0, iter310, loss: 0.949743926525116\n",
      "epoch0, iter320, loss: 0.7455096244812012\n",
      "epoch0, iter330, loss: 0.9379122853279114\n",
      "epoch0, iter340, loss: 0.844605028629303\n",
      "epoch0, iter350, loss: 0.5677027106285095\n",
      "epoch0, iter360, loss: 1.3987728357315063\n",
      "epoch0, iter370, loss: 0.9414189457893372\n",
      "epoch0, iter380, loss: 0.6540407538414001\n",
      "epoch0, iter390, loss: 0.6040262579917908\n",
      "epoch0, iter400, loss: 0.8898199200630188\n",
      "epoch0, iter410, loss: 0.8630444407463074\n",
      "epoch0, iter420, loss: 0.661899209022522\n",
      "epoch0, iter430, loss: 0.7873342037200928\n",
      "epoch0, iter440, loss: 0.5798068642616272\n",
      "epoch0, iter450, loss: 0.7752888798713684\n",
      "epoch0, iter460, loss: 0.6683440804481506\n",
      "epoch0, iter470, loss: 0.8011611104011536\n",
      "epoch0, iter480, loss: 0.6429539322853088\n",
      "epoch0, iter490, loss: 0.6015903353691101\n",
      "epoch0, iter500, loss: 1.0325186252593994\n",
      "epoch0, iter510, loss: 1.3384442329406738\n",
      "epoch0, iter520, loss: 0.8689532279968262\n",
      "epoch0, iter530, loss: 0.677577018737793\n",
      "epoch0, iter540, loss: 0.7476015686988831\n",
      "epoch0, iter550, loss: 0.5082968473434448\n",
      "epoch0, iter560, loss: 0.7153519988059998\n",
      "epoch0, iter570, loss: 0.5359604954719543\n",
      "epoch0, iter580, loss: 1.2330228090286255\n",
      "epoch0, iter590, loss: 0.6730768084526062\n",
      "epoch0, iter600, loss: 0.7048612236976624\n",
      "epoch0, iter610, loss: 0.6381247639656067\n",
      "epoch0, iter620, loss: 1.306540846824646\n",
      "epoch0, iter630, loss: 0.4743750989437103\n",
      "epoch0, iter640, loss: 0.4841291606426239\n",
      "epoch0, iter650, loss: 0.9021393656730652\n",
      "epoch0, iter660, loss: 0.519275963306427\n",
      "epoch0, iter670, loss: 0.7066236138343811\n",
      "epoch0, iter680, loss: 0.7042881846427917\n",
      "epoch0, iter690, loss: 0.7941648364067078\n",
      "epoch0, iter700, loss: 0.5590503215789795\n",
      "epoch0, iter710, loss: 0.6550703644752502\n",
      "epoch0, iter720, loss: 0.6258578896522522\n",
      "epoch0, iter730, loss: 0.41463354229927063\n",
      "epoch0, iter740, loss: 0.4861016571521759\n",
      "epoch0, iter750, loss: 0.6537637114524841\n",
      "epoch0, iter760, loss: 0.6508689522743225\n",
      "epoch0, iter770, loss: 0.384528249502182\n",
      "epoch0, iter780, loss: 0.5354824066162109\n",
      "epoch0, iter790, loss: 0.5754340291023254\n",
      "epoch0, iter800, loss: 0.7954073548316956\n",
      "epoch0, iter810, loss: 1.0037930011749268\n",
      "epoch0, iter820, loss: 0.7012612223625183\n",
      "epoch0, iter830, loss: 0.5982902646064758\n",
      "epoch0, iter840, loss: 0.6424938440322876\n",
      "epoch0, iter850, loss: 0.8615542054176331\n",
      "epoch0, iter860, loss: 0.8723037242889404\n",
      "epoch0, iter870, loss: 0.6552538871765137\n",
      "epoch0, iter880, loss: 0.6815762519836426\n",
      "epoch0, iter890, loss: 0.775770902633667\n",
      "epoch0, iter900, loss: 0.4977991282939911\n",
      "epoch0, iter910, loss: 0.584988534450531\n",
      "epoch0, iter920, loss: 0.8276796936988831\n",
      "epoch0, iter930, loss: 0.5228310823440552\n",
      "epoch0, iter940, loss: 1.4249147176742554\n",
      "epoch0, iter950, loss: 0.5590361952781677\n",
      "epoch0, iter960, loss: 0.6744347214698792\n",
      "epoch0, iter970, loss: 0.5727072358131409\n",
      "epoch0, iter980, loss: 0.5716967582702637\n",
      "epoch0, iter990, loss: 0.6409582495689392\n",
      "Finish epoch 0, time elapsed 779.7525627613068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a11e9e9a8432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mepochs\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Transfer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bcf5fcb7218b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, epochs, train_loader, val_loader, test_loader, use_gpu, name, debug)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# calculate val loss each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mval_loss_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mval_acc_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bcf5fcb7218b>\u001b[0m in \u001b[0;36mval\u001b[0;34m(model, val_loader, criterion, use_gpu)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mIOU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIOU\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "def checkM(prev, q=False):\n",
    "    out = {}\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                if obj.is_cuda and not q:\n",
    "                    name = str(obj.size())\n",
    "                    if name in out:\n",
    "                        out[name] += 1\n",
    "                    else:\n",
    "                        out[name] = 1\n",
    "                    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for key in out:\n",
    "        if key not in prev:\n",
    "            print(\"new: \" + key + \" : \" + str(out[key]))\n",
    "        elif prev[key] != out[key]:\n",
    "            #print(\"diff (new - old): \" + key + \" : \" + str(out[key] - prev[key]))\n",
    "            print(\"diff (new - old): \" + key + \" : \" + str(out[key])+ \" - \" +str(prev[key]))\n",
    "            \n",
    "    for key in prev:\n",
    "        if key not in out:\n",
    "            print(\"dropped: \" + key + \" : \" + str(prev[key]))\n",
    "    return out\n",
    "\n",
    "def memDiff(prev, out):\n",
    "    for key in out:\n",
    "        if key not in prev:\n",
    "            print(\"new: \" + key + \" : \" + str(out[key]))\n",
    "        elif prev[key] != out[key]:\n",
    "            print(\"diff (new - old): \" + key + \" : \" + str(out[key] - prev[key]))\n",
    "            \n",
    "    for key in prev:\n",
    "        if key not in out:\n",
    "            print(\"dropped: \" + key + \" : \" + str(prev[key]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 3\n",
    "    train_dataset = CityScapesDataset(csv_file='train.csv')\n",
    "    val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "    test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "    \n",
    "    \n",
    "    epochs     = 100\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Fix magic number\n",
    "    model = getTransferModel(34)\n",
    "    \n",
    "    \n",
    "    epochs     = 100\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    train(model, criterion, epochs, train_loader, val_loader, test_loader, use_gpu, \"Transfer\")\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('./save_param'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
