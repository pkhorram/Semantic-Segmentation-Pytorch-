{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.bias.data.view(m.bias.data.shape[0],1))\n",
    "        #a = math.sqrt(3) * math.sqrt(2/m.bias.data.shape[0])\n",
    "        #torch.nn.init._no_grad_uniform_(m.bias.data, -a, a)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def train(model, criterion, epochs, train_loader, val_loader, test_loader, use_gpu, name):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "    val_loss_set = []\n",
    "    val_acc_set = []\n",
    "    val_iou_set = []\n",
    "    \n",
    "    # Early Stop criteria\n",
    "    minLoss = 1e6\n",
    "    minLossIdx = 0\n",
    "    earliestStopEpoch = 10\n",
    "    earlyStopDelta = 5\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        \n",
    "        #print(np.array(val_loss).shape)\n",
    "        # early-stopping \n",
    "#         if epoch > 11:\n",
    "#             if val_loss[-1] < val_loss[-10]:\n",
    "#                 open('save_param', 'w').close()\n",
    "#                 torch.save(fcn_model.state_dict(), 'save_param')\n",
    "                \n",
    "                  \n",
    "        for iter, (inputs, tar, labels) in tqdm(enumerate(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            del tar\n",
    "            inputs = inputs.to(device)# Move your inputs onto the gpu\n",
    "            labels = labels.to(device) # Move your labels onto the gpu\n",
    "            \n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            del inputs\n",
    "            loss = criterion(outputs, Variable(labels.long()))\n",
    "            del labels\n",
    "            del outputs\n",
    "            loss.backward()\n",
    "            loss = loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss))\n",
    "        \n",
    "        \n",
    "        # calculate val loss each epoch\n",
    "        val_loss, val_acc, val_iou = val(model, val_loader, criterion, use_gpu)\n",
    "        \n",
    "        val_loss = val_loss.item()\n",
    "        \n",
    "        val_loss_set.append(val_loss)\n",
    "        val_acc_set.append(val_acc.item())\n",
    "        val_iou_set.append(val_iou.item())\n",
    "        \n",
    "        print(\"epoch {}, time {}, train loss {}, val loss {}, val acc {}, val iou {}\".format(epoch, time.time() - ts,\n",
    "                                                                                                loss.item(), val_loss.item(),\n",
    "                                                                                                val_acc.item(),\n",
    "                                                                                                val_iou.item()))\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < minLoss:\n",
    "            # Store new best\n",
    "            torch.save(model, name)\n",
    "            minLoss = val_loss\n",
    "            minLossIdx = epoch\n",
    "            \n",
    "        # If passed min threshold, and no new min has been reached for delta epochs\n",
    "        elif epoch > earliestStopEpoch and (epoch - minLossIdx) > earlyStopDelta:\n",
    "            print(\"Stopping early at {}\".format(minLossIdx))\n",
    "            break\n",
    "        # TODO what is this for?\n",
    "        #model.train()\n",
    "        \n",
    "    return val_loss_set, val_acc_set, val_iou_set\n",
    "\n",
    "\n",
    "def val(model, val_loader, criterion, use_gpu):\n",
    "    \n",
    "    # set to evaluation mode \n",
    "    model.eval()\n",
    "\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    loss = []\n",
    "    pred = []\n",
    "    acc = []\n",
    "    \n",
    "    IOU_init = False\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        \n",
    "        #model.to(device)\n",
    "        \n",
    "    for iter, (X, tar, Y) in tqdm(enumerate(val_loader)):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,tar.shape[1]))\n",
    "            \n",
    "        if use_gpu:\n",
    "            inputs = X.to(device)\n",
    "            labels = Y.to(device)\n",
    "            \n",
    "        else:\n",
    "            inputs, labels = X, Y\n",
    "\n",
    "            \n",
    "        with torch.no_grad():   \n",
    "            outputs = model(inputs)\n",
    "            del inputs\n",
    "            loss.append(criterion(outputs, labels.long()).item())\n",
    "            prediction = softmax(outputs) \n",
    "            acc.append(pixel_acc(prediction, labels).item())\n",
    "            IOU = IOU + np.array(iou(prediction, labels))\n",
    "        \n",
    "    \n",
    "    acc = sum(acc)/len(acc)\n",
    "    avg_loss = sum(loss)/len(loss) \n",
    "    IOU = IOU/iter  \n",
    "    \n",
    "    return avg_loss, acc, IOU      \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "def test(model, use_gpu):\n",
    "    \n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    pred = []\n",
    "    acc = []\n",
    "    if use_gpu:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        \n",
    "        model.to(device)\n",
    "    \n",
    "    IOU_init = False\n",
    "    for iter, (X, tar, Y) in enumerate(test_loader):\n",
    "        \n",
    "        if not IOU_init:\n",
    "            IOU_init = True\n",
    "            IOU = np.zeros((1,tar.shape[1]))\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = X.to(device)\n",
    "            labels = Y.to(device)\n",
    "        else:\n",
    "            inputs, labels = X, Y\n",
    "                    \n",
    "        \n",
    "        outputs = model(inputs)  \n",
    "        \n",
    "        prediction = softmax(outputs)\n",
    "        acc.append(pixel_acc(prediction, labels))\n",
    "        IOU = IOU + np.array(iou(prediction, Y))\n",
    "        \n",
    "    acc = sum(acc)/len(acc)        \n",
    "    IOU = IOU/iter\n",
    "\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    \n",
    "    return acc, IOU\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, loss: 3.7059175968170166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:05,  2.03s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 10.92 GiB total capacity; 7.38 GiB already allocated; 863.50 MiB free; 2.18 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3110b101f342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#         fcn_model.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#     val(fcn_model, val_loader, criterion, use_gpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8a12f8569f6e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, epochs, train_loader, val_loader, test_loader, use_gpu, name)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 10.92 GiB total capacity; 7.38 GiB already allocated; 863.50 MiB free; 2.18 GiB cached)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_dataset = CityScapesDataset(csv_file='train.csv')\n",
    "    val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "    test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=1,\n",
    "                          num_workers=10,\n",
    "                          shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=2,\n",
    "                          num_workers=10,\n",
    "                          shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=4,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "    \n",
    "    \n",
    "    epochs     = 100\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Fix magic number\n",
    "    #model = FCN(n_class=34)\n",
    "    model = Unet(n_class=34)\n",
    "    model.apply(init_weights)\n",
    "    #fcn_model = torch.load('FCN')\n",
    "    \n",
    "    epochs     = 100\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "#     if use_gpu:s\n",
    "#         device = torch.device(\"cuda:0\")\n",
    "#         fcn_model = torch.nn.DataParallel(fcn_model)\n",
    "#         fcn_model.to(device)\n",
    "#     val(fcn_model, val_loader, criterion, use_gpu)\n",
    "    train(model, criterion, epochs, train_loader, val_loader, test_loader, use_gpu, \"Unet\")\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load('./save_param'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
